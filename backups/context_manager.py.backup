"""
Borgo-Bot v3.5 - Context Manager
Phase 3: Strikte Context-Isolierung und Size-Management
"""

import yaml
import logging
from typing import List, Dict, Set, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass

from config import (
    MAX_CONTEXT_WORDS,
    MAX_CONTEXT_ENTRIES,
    YAML_DB_PATH,
    CONTEXT_MIXING_RULES
)

logger = logging.getLogger(__name__)


@dataclass
class ContextEntry:
    """ReprÃ¤sentiert einen einzelnen Context-Eintrag"""
    keyword: str
    category: str
    content: str
    word_count: int
    metadata: Dict


class ContextManager:
    """
    Verwaltet Context fÃ¼r LLM-Anfragen
    Verhindert Context-Mixing und Halluzinationen
    """
    
    def __init__(self, yaml_path: Path = YAML_DB_PATH):
        self.yaml_path = yaml_path
        self.knowledge_base = self._load_yaml()
        self.synonym_map = self._build_synonym_map()
        self.stats = {
            'contexts_built': 0,
            'entries_loaded': 0,
            'truncations': 0,
            'mixing_prevented': 0,
        }
    
    def _load_yaml(self) -> Dict:
        """LÃ¤dt YAML Knowledge Base"""
        try:
            with open(self.yaml_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
                logger.info(f"âœ… YAML loaded: {len(data)} entries")
                return data
        except Exception as e:
            logger.error(f"âŒ Failed to load YAML: {e}")
            return {}
    
    def _build_synonym_map(self) -> Dict[str, str]:
        """Baut Mapping: Synonym zu Entry-Name"""
        synonym_map = {}
        
        for entry_name, entry_data in self.knowledge_base.items():
            synonym_map[entry_name.lower()] = entry_name
            
            if 'synonyms' in entry_data:
                for synonym in entry_data['synonyms']:
                    synonym_map[synonym.lower()] = entry_name
        
        logger.debug(f"Built synonym map with {len(synonym_map)} mappings")
        return synonym_map
    
    def get_available_keywords(self) -> Set[str]:
        """Gibt alle verfÃ¼gbaren Keywords zurÃ¼ck"""
        all_keywords = set()
        
        for entry_name, entry_data in self.knowledge_base.items():
            all_keywords.add(entry_name)
            
            if 'synonyms' in entry_data:
                all_keywords.update(entry_data['synonyms'])
        
        return all_keywords

    def build_context(
        self, 
        keywords: List[str], 
        query: str,
        max_entries: int = MAX_CONTEXT_ENTRIES
    ) -> Tuple[str, Dict]:
        """Baut Context aus Keywords"""
        self.stats['contexts_built'] += 1
        
        entries = self._load_entries(keywords, max_entries)
        entries = self._prevent_context_mixing(entries, query)
        entries = self._truncate_by_word_count(entries)
        context_string = self._format_context(entries)
        
        metadata = {
            'total_entries': len(entries),
            'total_words': sum(e.word_count for e in entries),
            'keywords_used': [e.keyword for e in entries],
            'categories': list(set(e.category for e in entries)),
        }
        
        logger.info(f"ðŸ“¦ Context built: {len(entries)} entries, {metadata['total_words']} words")
        
        return context_string, metadata
    
    def _load_entries(
        self, 
        keywords: List[str], 
        max_entries: int
    ) -> List[ContextEntry]:
        """LÃ¤dt YAML-Entries fÃ¼r Keywords"""
        entries = []
        seen_entries = set()
        
        for keyword in keywords[:max_entries]:
            entry_name = self.synonym_map.get(keyword.lower(), keyword)
            
            if entry_name in seen_entries:
                continue
            
            if entry_name in self.knowledge_base:
                data = self.knowledge_base[entry_name]
                
                entry = ContextEntry(
                    keyword=entry_name,
                    category=data.get('category', 'unknown'),
                    content=data.get('content', ''),
                    word_count=len(data.get('content', '').split()),
                    metadata={
                        'synonyms': data.get('synonyms', []),
                        'priority': data.get('priority', 'normal'),
                    }
                )
                
                entries.append(entry)
                seen_entries.add(entry_name)
                self.stats['entries_loaded'] += 1
                
                logger.debug(f"Loaded entry: {entry_name} from keyword: {keyword}")
        
        return entries
    
    def _prevent_context_mixing(
        self, 
        entries: List[ContextEntry], 
        query: str
    ) -> List[ContextEntry]:
        """Verhindert Context-Mixing"""
        if not entries:
            return entries
        
        query_lower = query.lower()
        filtered_entries = []
        
        for entry in entries:
            should_keep = True
            
            if entry.keyword in CONTEXT_MIXING_RULES:
                forbidden_words = CONTEXT_MIXING_RULES[entry.keyword]
                
                for other_entry in entries:
                    if other_entry.keyword == entry.keyword:
                        continue
                    
                    other_content_lower = other_entry.content.lower()
                    for forbidden in forbidden_words:
                        if forbidden in other_content_lower:
                            logger.warning(
                                f"Context mixing detected: '{entry.keyword}' conflicts with "
                                f"'{other_entry.keyword}' (contains '{forbidden}')"
                            )
                            should_keep = False
                            self.stats['mixing_prevented'] += 1
                            break
                    
                    if not should_keep:
                        break
            
            if should_keep:
                filtered_entries.append(entry)
        
        return filtered_entries
    
    def _truncate_by_word_count(
        self, 
        entries: List[ContextEntry]
    ) -> List[ContextEntry]:
        """Begrenzt Entries auf MAX_CONTEXT_WORDS"""
        total_words = 0
        truncated_entries = []
        
        for entry in entries:
            if total_words + entry.word_count <= MAX_CONTEXT_WORDS:
                truncated_entries.append(entry)
                total_words += entry.word_count
            else:
                logger.warning(
                    f"Truncating context: '{entry.keyword}' would exceed limit "
                    f"({total_words + entry.word_count} > {MAX_CONTEXT_WORDS})"
                )
                self.stats['truncations'] += 1
                break
        
        return truncated_entries
    
    def _format_context(self, entries: List[ContextEntry]) -> str:
        """Formatiert Entries zu LLM-Context-String"""
        if not entries:
            return ""
        
        context_parts = [
            "# BORGO BATONE KNOWLEDGE BASE",
            "",
            "Du bist Borgi, der Borgo-Batone GÃ¤ste-Assistent.",
            "Antworte NUR basierend auf folgenden Informationen:",
            ""
        ]
        
        for i, entry in enumerate(entries, 1):
            context_parts.extend([
                f"## {i}. {entry.keyword.upper()} (Kategorie: {entry.category})",
                "",
                entry.content,
                "",
                "---",
                ""
            ])
        
        context_parts.extend([
            "# WICHTIGE REGELN",
            "1. Antworte NUR mit Informationen aus obigen EintrÃ¤gen",
            "2. Wenn du etwas nicht weiÃŸt, sage es ehrlich",
            "3. Erfinde KEINE Zahlen, Einheiten oder Details",
            "4. Bleibe beim Thema - keine Themenvermischung",
            "5. Sei prÃ¤zise und korrekt",
        ])
        
        return "\n".join(context_parts)
    
    def get_fallback_context(self, category: Optional[str] = None) -> str:
        """Gibt Fallback-Context wenn keine Keywords gefunden"""
        logger.info(f"Using fallback context (category: {category})")
        
        fallback = [
            "# BORGO BATONE - ALLGEMEINE INFORMATIONEN",
            "",
            "Borgo Batone ist ein historisches Dorf in der Toskana.",
            "Es ist ein gemeinschaftliches Projekt mit 100 Mitgliedern.",
            "",
            "Ich kann dir helfen bei Fragen zu:",
            "â€¢ WLAN und Internet",
            "â€¢ Pizzaofen Benutzung",
            "â€¢ MÃ¼ll und Recycling",
            "â€¢ Haustiere (besonders Hunde)",
            "â€¢ Sicherheit (Schlangen, NotfÃ¤lle)",
            "â€¢ Kontakt zur Onsite-Gruppe",
            "",
            "FÃ¼r deine spezifische Frage habe ich leider keine Details.",
            "Bitte kontaktiere die Onsite-Gruppe oder schaue im Benvenuti-Guide nach."
        ]
        
        return "\n".join(fallback)
    
    def reload_knowledge_base(self) -> bool:
        """LÃ¤dt Knowledge Base neu"""
        try:
            self.knowledge_base = self._load_yaml()
            self.synonym_map = self._build_synonym_map()
            logger.info("âœ… Knowledge base reloaded")
            return True
        except Exception as e:
            logger.error(f"âŒ Failed to reload knowledge base: {e}")
            return False
    
    def get_stats(self) -> Dict:
        """Gibt Context-Manager Statistiken zurÃ¼ck"""
        return {
            **self.stats,
            'total_entries_in_db': len(self.knowledge_base),
            'total_synonym_mappings': len(self.synonym_map),
            'avg_entries_per_context': (
                self.stats['entries_loaded'] / self.stats['contexts_built']
                if self.stats['contexts_built'] > 0 else 0
            )
        }


class ContextValidator:
    """Validiert generierten Context auf QualitÃ¤t"""
    
    @staticmethod
    def validate(context: str, metadata: Dict) -> Tuple[bool, List[str]]:
        """Validiert Context"""
        issues = []
        
        if not context or len(context.strip()) < 50:
            issues.append("Context zu kurz oder leer")
        
        word_count = len(context.split())
        if word_count > MAX_CONTEXT_WORDS * 1.2:
            issues.append(f"Context zu groÃŸ: {word_count} WÃ¶rter")
        
        keywords = metadata.get('keywords_used', [])
        if len(keywords) != len(set(keywords)):
            issues.append("Doppelte Keywords im Context")
        
        categories = metadata.get('categories', [])
        if len(categories) > 2:
            issues.append(f"Zu viele Kategorien gemischt: {categories}")
        
        is_valid = len(issues) == 0
        
        if not is_valid:
            logger.warning(f"Context validation failed: {issues}")
        
        return is_valid, issues
